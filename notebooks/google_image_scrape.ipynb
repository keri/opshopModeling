{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import json\n",
    "import urllib.request as urllib2\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding path to geckodriver to the OS environment variable\n",
    "# assuming that it is stored at the same path as this script\n",
    "os.environ[\"PATH\"] += os.pathsep + os.getcwd()\n",
    "download_path = \"dataset/\"\n",
    "\n",
    "def main(searchtext, n):\n",
    "    searchtext =  searchtext #search query\n",
    "    num_requested = n # number of images to download\n",
    "    number_of_scrolls = int(num_requested / 400 + 1)\n",
    "    # number_of_scrolls * 400 images will be opened in the browser\n",
    "\n",
    "    if not os.path.exists(download_path + searchtext.replace(\" \", \"_\")):\n",
    "        os.makedirs(download_path + searchtext.replace(\" \", \"_\"))\n",
    "\n",
    "    url = \"https://www.google.co.in/search?q=\"+searchtext+\"&source=lnms&tbm=isch\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    \n",
    "    headers = {}\n",
    "    #headers['User-Agent'] = \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome 74.0.3729.169 Safari/537.36\"\n",
    "    headers['User-Agent'] = \"Chrome 74.0.3729.169\"\n",
    "    extensions = {\"jpg\", \"jpeg\"}\n",
    "    img_count = 0\n",
    "    downloaded_img_count = 0\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//input[@value='Show more results']\").click()\n",
    "    except Exception as e:\n",
    "        print (\"Less images found:\", e)\n",
    "        #break\n",
    "        \n",
    "    for _ in range(number_of_scrolls):\n",
    "        for __ in range(10):\n",
    "            # multiple scrolls needed to show all 400 images\n",
    "            driver.execute_script(\"window.scrollBy(0, 1000000)\")\n",
    "            time.sleep(0.2)\n",
    "        # to load next 400 images\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # imges = driver.find_elements_by_xpath('//div[@class=\"rg_meta\"]') # not working anymore\n",
    "    imges = driver.find_elements_by_xpath('//div[contains(@class,\"rg_meta\")]')\n",
    "    print (\"Total images:\", len(imges), \"\\n\")\n",
    "    for img in imges:\n",
    "        img_count += 1\n",
    "        img_url = json.loads(img.get_attribute('innerHTML'))[\"ou\"]\n",
    "        if 'oldnavy' in str('{}'.format(img_url)):\n",
    "            print('olnavy in url ..')\n",
    "            pass\n",
    "        elif 'gap' in str('{}'.format(img_url)):\n",
    "            print('gap in url ..')\n",
    "            pass\n",
    "        elif 'express' in str('{}'.format(img_url)):\n",
    "            print('express in url ..')\n",
    "            pass\n",
    "        elif 'childrensplace' in str('{}'.format(img_url)):\n",
    "            print('express in url ..')\n",
    "            pass\n",
    "        else:\n",
    "            img_type = json.loads(img.get_attribute('innerHTML'))[\"ity\"]\n",
    "            print (\"Downloading image\", img_count, \": \", img_url)\n",
    "            try:\n",
    "                if img_type not in extensions:\n",
    "                    img_type = \"jpg\"\n",
    "                req = urllib2.Request(img_url, headers=headers)\n",
    "                raw_img = urllib2.urlopen(req).read()\n",
    "                f = open(download_path+searchtext.replace(\" \", \"_\")+\"/\"+str(downloaded_img_count)+\".\"+img_type, \"wb\")\n",
    "                f.write(raw_img)\n",
    "                f.close\n",
    "                downloaded_img_count += 1\n",
    "            except Exception as e:\n",
    "                print (\"Download failed:\", e)\n",
    "            finally:\n",
    "                print ()\n",
    "            if downloaded_img_count >= num_requested:\n",
    "                break\n",
    "\n",
    "    print (\"Total downloaded: \", downloaded_img_count, \"/\", img_count)\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main('bermuda shorts', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'oldnavy' in str('https://oldnavy.gap.com/webcontent/0016/430/120/cn16430120.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
